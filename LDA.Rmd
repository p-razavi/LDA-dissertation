---
title: "LDA on Anger Narratives"
author: "Pooya Razavi"
date: "last knitted: `r Sys.time()`"
output: 
  html_document:
    theme: cosmo
    highlight: textmate
    toc: TRUE
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(dplyr)
library(tidytext)

df <- readxl::read_xlsx("C:/Users/pooya/Dropbox (University of Oregon)/Anger Dissertation/Prototype study analysis/dataset1/ProcessedData_PR.F21.xlsx")

#set up categorical variables
df <- df %>% 
          mutate(NarrativeWritten = as.factor(df$NarrativeWritten),
                 NarrativeRelevant = as.factor(df$NarrativeRelevant),
                 Condition = as.factor(df$Condition),
                 gender = as.factor(df$gender))

#assigning values to factor levels
  levels(df$NarrativeWritten) <- c("No", "Yes")

  levels(df$NarrativeRelevant) <- c("No", "Yes", NA) #note: This needs to be updated in the dataset after all naratives have been coded by RAs

  levels(df$Condition) <- c("justified", "nonjustified", NA)
  levels(df$gender) <- c("female", "male", "non-binary", "self-describe", "prefer_not")

knitr::opts_chunk$set(echo = TRUE)
```


# Create the dataframe for text analysis

```{r}
df2 <- df %>% 
          dplyr::filter(NarrativeRelevant == "Yes") %>% 
          dplyr::select(Duration__in_seconds_, ResponseId, right_narrative, nonright_narrative, Condition, 
                        anger_feel, anger_express, who_caused, gender) %>% 
          dplyr::rename("duration" = "Duration__in_seconds_",
                        "id" = "ResponseId",
                        "justified_nar" = "right_narrative",
                        "notjustified_nar" = "nonright_narrative",
                        "condition" = "Condition") %>% 
          dplyr::mutate(all_narratives = dplyr::coalesce(justified_nar, notjustified_nar))


```

# Preparing the document

```{r}
#tokenize the text
tokenized_narratives <- df2 %>% 
                            dplyr::select(id, , condition, all_narratives) %>% 
                            tidytext::unnest_tokens(input = all_narratives,
                                                    output = word,
                                                    format = "text",
                                                    token = "words",
                                                    drop = TRUE,
                                                    to_lower = TRUE)
glimpse(tokenized_narratives)

#for each narrative, how many times each word appears
tokenized_narratives %>% 
    count(id, word) %>% 
    print(n = 20)

#get the top 3 words for each narrative
tokenized_narratives %>% 
    count(id, word) %>% 
    group_by(id) %>% 
    arrange(desc(n)) %>% 
    filter(row_number() < 4) %>% 
    ungroup() %>% 
    print(n = 20)

#create a document-term-matrix
  dtm <-  tokenized_narratives %>% 
          count(id, word) %>% 
          tidytext::cast_dtm(document = id,
                             term = word,
                             value = n)
  

```


# Run the LDA model

```{r}
lda_model <- topicmodels::LDA(x = dtm, k = 2, method = "Gibbs",
                 control = list(alpha = 1, delta = 0.1, seed = 110))
#probability of each topic for each narrative
topicmodels::posterior(lda_model)$topics %>% 
  head(20)

```

